{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy import signal\n",
    "from scipy.fftpack import fft\n",
    "from scipy import ndimage\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#annots = loadmat('C:\\\\Users\\\\llinc\\\\GitHub\\\\retina_personal\\\\0406\\\\merge\\\\merge_0224_HMM_RL_G2.5_5min_Q100_6.5mW.mat')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EqualState assign states with equal possibility for input array x\n",
    "def EqualState(x, num_state):\n",
    "    xs=np.sort(x)\n",
    "    binlen=int(len(x)/num_state-0.5) #round\n",
    "    edges = xs[np.arange(num_state+1)*binlen]\n",
    "    xstate=np.zeros(len(x))\n",
    "    for i in range(num_state):\n",
    "        xstate[x>=edges[i]] = i\n",
    "    xstate = xstate.astype(int)\n",
    "    return xstate, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PIfunc(r, x, v, dt, window):\n",
    "    negshift=window[0] # second\n",
    "    posshift=window[1] # second\n",
    "    shiftlen=(posshift-negshift)/dt+1\n",
    "    timeshift=np.linspace(negshift,posshift,int(shiftlen))\n",
    "    bitshift=np.linspace(negshift/dt,posshift/dt,int(shiftlen),dtype = 'int16')\n",
    "    Information = dict()\n",
    "    Information[('BROJA_2PID','SI')]=np.zeros(len(bitshift))\n",
    "    Information[('BROJA_2PID','UIx')]=np.zeros(len(bitshift))\n",
    "    Information[('BROJA_2PID','UIv')]=np.zeros(len(bitshift))\n",
    "    Information[('BROJA_2PID','CI')]=np.zeros(len(bitshift))\n",
    "    Information[('Beer','Red')]=np.zeros(len(bitshift))\n",
    "    Information[('Beer','UIx')]=np.zeros(len(bitshift))\n",
    "    Information[('Beer','UIv')]=np.zeros(len(bitshift))\n",
    "    Information[('Beer','Syn')]=np.zeros(len(bitshift))\n",
    "    \n",
    "    Information[('test','SI')]=np.zeros(len(bitshift))\n",
    "    Information[('test','UIx')]=np.zeros(len(bitshift))\n",
    "    Information[('test','UIv')]=np.zeros(len(bitshift))\n",
    "    Information[('test','CI')]=np.zeros(len(bitshift))\n",
    "    # shifted data\n",
    "    # shift>0 => y shifted to positive side\n",
    "    for i in range(len(bitshift)):\n",
    "        xx=[]\n",
    "        vv=[]\n",
    "        rr=[]\n",
    "        shift=bitshift[i]\n",
    "        if shift>0:\n",
    "            xx=x[shift:]\n",
    "            vv=v[shift:]\n",
    "            rr=r[:(-1*shift)]\n",
    "        elif shift==0:\n",
    "            xx=x\n",
    "            vv=v\n",
    "            rr=r\n",
    "        elif shift<0:\n",
    "            xx=x[:shift]\n",
    "            vv=v[:shift]\n",
    "            rr=r[(-1*shift):]\n",
    "        #find weight of each states by 3D histogram \n",
    "        xedges = np.append(np.unique(xx),(max(xx)+1))\n",
    "        vedges = np.append(np.unique(vv),(max(vv)+1))\n",
    "        redges = np.append(np.unique(rr),(max(rr)+1))\n",
    "        dat = np.concatenate((xx[:,np.newaxis], vv[:,np.newaxis],rr[:,np.newaxis]), axis=1)\n",
    "        N, edges = np.histogramdd(dat, bins=(xedges, vedges, redges))\n",
    "        #Calculate all kinds of probability and make sure the shape of them, 0 -> x, 1 -> v, 2 -> r\n",
    "        px=(np.sum(N,axis=(1,2))/np.sum(N))[:, np.newaxis, np.newaxis]\n",
    "        pv=(np.sum(N,axis=(0,2))/np.sum(N))[np.newaxis, :, np.newaxis]\n",
    "        pr=(np.sum(N,axis=(0,1))/np.sum(N))[np.newaxis ,np.newaxis, :]\n",
    "        pxv=(np.sum(N,axis=2)/np.sum(N))[:, :, np.newaxis]\n",
    "        pxr=(np.sum(N,axis=1)/np.sum(N))[:, np.newaxis, :]\n",
    "        pvr=(np.sum(N,axis=0)/np.sum(N))[np.newaxis, :, :]\n",
    "        pxvr=(N/np.sum(N))\n",
    "        \n",
    "        Information[('test','UIx')][i] = np.nansum(pxvr*np.log2(pxvr*px/pxv/pxr))/dt\n",
    "        Information[('test','UIv')][i] = np.nansum(pxvr*np.log2(pxvr*pv/pxv/pvr))/dt\n",
    "\n",
    "\n",
    "        MIxr=np.nansum(pxr*np.log2(pxr/px/pr))/dt\n",
    "        MIvr=np.nansum(pvr*np.log2(pvr/pv/pr))/dt\n",
    "        MIxvR=np.nansum(pxvr*np.log2(pxvr/pxv/pr))/dt\n",
    "        PI_xR = np.nansum(pxr*np.log2(pxr/px/pr), axis = (0,1))\n",
    "        PI_vR = np.nansum(pvr*np.log2(pvr/pv/pr), axis = (0,1))\n",
    "        R = sum(np.minimum(PI_xR, PI_vR))/dt\n",
    "        Information[('Beer','Red')][i] = R\n",
    "        Information[('Beer','UIx')][i] = MIxr - R\n",
    "        Information[('Beer','UIv')][i] = MIvr - R\n",
    "        Information[('Beer','Syn')][i] = MIxvR - MIxr - MIvr + R\n",
    "\n",
    "    return timeshift, Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spike_Time_Generater(rdt, dt, Garmma=1):\n",
    "    rdt = rdt*Garmma\n",
    "    Spike_time = []\n",
    "    \n",
    "    counter = 0\n",
    "    post_remainer_c = 0\n",
    "    p = 1\n",
    "    while True:\n",
    "        the_random_number = 1-np.random.rand()\n",
    "        while (the_random_number < p and counter < len(rdt)):\n",
    "            p *= np.exp(-rdt[counter])\n",
    "            counter += 1\n",
    "        if counter >= len(rdt):\n",
    "            break\n",
    "        remainer_c = -np.log(p/the_random_number)/rdt[counter-1]\n",
    "#         if remainer_c>=1 or remainer_c<=0:\n",
    "#             print('shit!')\n",
    "        Spike_time.append(dt*(counter-remainer_c))\n",
    "        p = np.exp(-remainer_c*rdt[counter-1])\n",
    "    return Spike_time[::Garmma]\n",
    "\n",
    "# activation function\n",
    "def NL(x,theta=0):\n",
    "    y = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        if x[i]- theta>0:\n",
    "            y[i]= x[i]-theta\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chose file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_folder = 'D:\\\\GoogleDrive\\\\retina\\\\Exps\\\\2020\\\\0503'\n",
    "# G = 4.5\n",
    "# annots = loadmat(exp_folder+'\\\\merge\\\\'+'merge_0224_OUsmooth_RL_G'+str(G)+'_5min_Q100_6.5mW_1Hz.mat')\n",
    "\n",
    "# exp_folder = 'D:\\\\GoogleDrive\\\\retina\\\\Exps\\\\2020\\\\0729'\n",
    "# Fc = 8\n",
    "# annots = loadmat(exp_folder+'\\\\merge\\\\'+'merge_0727_OUsmooth_Bright_UL_DR_G4.5_5min_Q100_6.5mW_'+str(Fc)+'Hz.mat')\n",
    "\n",
    "exp_folder = 'D:\\\\GoogleDrive\\\\retina\\\\Chou\\'s data\\\\20200408'\n",
    "Fc_list = [2,4,7,10]\n",
    "annots_list = []\n",
    "for Fc in Fc_list:\n",
    "    annots_list.append(loadmat(exp_folder+'\\\\20200408_OU_cutoff='+str(Fc)+'_sort_unit2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.01\n",
    "sampling_rate = 20000\n",
    "x_list, v_list, t_cor_list, T_list = [], [], [], []\n",
    "for annots in annots_list:\n",
    "    TimeStamps =np.round(np.squeeze(annots['TimeStamps']))\n",
    "    TimeStamps = TimeStamps.astype(int)\n",
    "    x = annots['a_data'][0, TimeStamps[0]*sampling_rate:TimeStamps[1]*sampling_rate+1]\n",
    "    x = ndimage.gaussian_filter1d(x, sigma=int(sampling_rate*dt/2), mode='reflect') / dt\n",
    "    x = x[::int(sampling_rate*dt)]\n",
    "    x = x.astype(float)\n",
    "    x = (x -np.mean(x))/np.std(x)\n",
    "    T = np.arange(1,len(x)+1)*dt\n",
    "    v = np.append(0,np.diff(x))/dt\n",
    "    \n",
    "    x_list.append(x.copy())\n",
    "    v_list.append(v.copy())\n",
    "    T_list.append(T.copy())\n",
    "    x_cor = np.correlate(x, x, \"same\")\n",
    "    x_cor = x_cor[:int((len(x_cor)+1)/2)+1]\n",
    "    Taxis = np.flip(T[:len(x_cor)]-dt*3/2)\n",
    "    t_cor_list.append(np.interp(0.5*max(x_cor),  x_cor, Taxis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambdas =  np.arange(0.05,0.95,0.02)\n",
    "betas = (1-Lambdas)/Lambdas\n",
    "alpha = 100. #1/sec\n",
    "K = 100.\n",
    "g = 75.\n",
    "phi = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.05 18.999999999999996\n",
      "2 0.07 13.285714285714283\n",
      "2 0.09000000000000001 10.11111111111111\n",
      "2 0.11000000000000001 8.09090909090909\n"
     ]
    }
   ],
   "source": [
    "##response\n",
    "# Model one: simple estimation\n",
    "window = [-1,1] # second\n",
    "Ux_peaktime_list =[]\n",
    "Uv_peaktime_list = []\n",
    "Syn_peaktime_list = []\n",
    "Rdn_peaktime_list = []\n",
    "MIx_peaktime_list = []\n",
    "MIv_peaktime_list = []\n",
    "MIxv_peaktime_list = []\n",
    "\n",
    "Ux_peakH_list =[]\n",
    "Uv_peakH_list = []\n",
    "Syn_peakH_list = []\n",
    "Rdn_peakH_list = []\n",
    "MIx_peakH_list = []\n",
    "MIv_peakH_list = []\n",
    "MIxv_peakH_list = []\n",
    "\n",
    "ngd_Ux_peaktime_list =[]\n",
    "ngd_Uv_peaktime_list = []\n",
    "ngd_Syn_peaktime_list = []\n",
    "ngd_Rdn_peaktime_list = []\n",
    "ngd_MIx_peaktime_list = []\n",
    "ngd_MIv_peaktime_list = []\n",
    "ngd_MIxv_peaktime_list = []\n",
    "\n",
    "ngd_Ux_peakH_list =[]\n",
    "ngd_Uv_peakH_list = []\n",
    "ngd_Syn_peakH_list = []\n",
    "ngd_Rdn_peakH_list = []\n",
    "ngd_MIx_peakH_list = []\n",
    "ngd_MIv_peakH_list = []\n",
    "ngd_MIxv_peakH_list = []\n",
    "for i in range(len(annots_list)):\n",
    "    Ux_peaktime =[]\n",
    "    Uv_peaktime = []\n",
    "    Syn_peaktime = []\n",
    "    Rdn_peaktime = []\n",
    "    MIx_peaktime = []\n",
    "    MIv_peaktime = []\n",
    "    MIxv_peaktime = []\n",
    "    Ux_peakH =[]\n",
    "    Uv_peakH = []\n",
    "    Syn_peakH = []\n",
    "    Rdn_peakH = []\n",
    "    MIx_peakH = []\n",
    "    MIv_peakH = []\n",
    "    MIxv_peakH = []\n",
    "    \n",
    "    ngd_Ux_peaktime =[]\n",
    "    ngd_Uv_peaktime = []\n",
    "    ngd_Syn_peaktime = []\n",
    "    ngd_Rdn_peaktime = []\n",
    "    ngd_MIx_peaktime = []\n",
    "    ngd_MIv_peaktime = []\n",
    "    ngd_MIxv_peaktime = []\n",
    "    ngd_Ux_peakH =[]\n",
    "    ngd_Uv_peakH = []\n",
    "    ngd_Syn_peakH = []\n",
    "    ngd_Rdn_peakH = []\n",
    "    ngd_MIx_peakH = []\n",
    "    ngd_MIv_peakH = []\n",
    "    ngd_MIxv_peakH = []\n",
    "\n",
    "    x = x_list[i]\n",
    "    v = v_list[i]\n",
    "    for Lambda in Lambdas:\n",
    "        \n",
    "        beta = (1-Lambda)/Lambda\n",
    "        print(Fc_list[i], Lambda, beta)\n",
    "        y=np.zeros(len(T_list[i]))\n",
    "        z=np.zeros(len(T_list[i]))\n",
    "        for j in range(len(T_list[i])-1):\n",
    "#             g= beta\n",
    "            dy=dt*(-alpha*y[j]+K*(x[j]-phi*z[j]))\n",
    "            dz=dt*(-beta*z[j]+g*y[j])\n",
    "            y[j+1]=y[j]+dy\n",
    "            z[j+1]=z[j]+dz\n",
    "        #assign states\n",
    "        r = NL(np.mean(y)-y, 0)\n",
    "        ratio = sum(r)/T_list[i][-1]/12\n",
    "        FakeSpike = Spike_Time_Generater(r/ratio, dt, 10)\n",
    "        rstate, _ = np.histogram(FakeSpike, np.append(0,T_list[i]))\n",
    "        #rstate = np.random.poisson(rstate)\n",
    "        rstate = rstate.astype(int)\n",
    "        xstate,edge = EqualState(x, 6)\n",
    "        vstate,edge = EqualState(v, 6)\n",
    "        #calculate information\n",
    "        timeshift, Information = PIfunc(rstate, xstate, vstate, dt, window)\n",
    "        Ux = Information[('Beer','UIx')]\n",
    "        Uv = Information[('Beer','UIv')]\n",
    "        Syner = Information[('Beer','Syn')]\n",
    "        Redun = Information[('Beer','Red')]\n",
    "#         ax.plot(Ux+Uv+Redun+Syner)\n",
    "        #find peak\n",
    "        ngd_Ux_peaktime.append( timeshift[int(np.mean(np.where(Ux == max(Ux))))])\n",
    "        ngd_Uv_peaktime.append( timeshift[int(np.mean(np.where(Uv == max(Uv))))])\n",
    "        ngd_Syn_peaktime.append( timeshift[int(np.mean(np.where(Syner == max(Syner))))])\n",
    "        ngd_Rdn_peaktime.append( timeshift[int(np.mean(np.where(Redun == max(Redun))))])\n",
    "        ngd_MIx_peaktime.append( timeshift[np.argmax(Ux+Redun)])\n",
    "        ngd_MIv_peaktime.append( timeshift[np.argmax(Uv+Redun)])\n",
    "        ngd_MIxv_peaktime.append( timeshift[np.argmax(Ux+Uv+Redun+Syner)])\n",
    "        \n",
    "        ngd_Ux_peakH.append( max(Ux))\n",
    "        ngd_Uv_peakH.append( max(Uv))\n",
    "        ngd_Syn_peakH.append( max(Syner))\n",
    "        ngd_Rdn_peakH.append( max(Redun))\n",
    "        ngd_MIx_peakH.append( max(Ux+Redun))\n",
    "        ngd_MIv_peakH.append( max(Uv+Redun))\n",
    "        ngd_MIxv_peakH.append( max(Ux+Uv+Redun+Syner))\n",
    "        \n",
    "        r1 = (1-Lambda)*x+Lambda*v\n",
    "        r = NL(np.mean(r1)-r1, 0)\n",
    "        ratio = sum(r)/T_list[i][-1]/12\n",
    "        FakeSpike = Spike_Time_Generater(r/ratio, dt, 10)\n",
    "        rstate, _ = np.histogram(FakeSpike, np.append(0,T_list[i]))\n",
    "        #rstate = np.random.poisson(rstate)\n",
    "        rstate = rstate.astype(int)\n",
    "        xstate,edge = EqualState(x, 6)\n",
    "        vstate,edge = EqualState(v, 6)\n",
    "        #calculate information\n",
    "        timeshift, Information = PIfunc(rstate, xstate, vstate, dt, window)\n",
    "        Ux = Information[('Beer','UIx')]\n",
    "        Uv = Information[('Beer','UIv')]\n",
    "        Syner = Information[('Beer','Syn')]\n",
    "        Redun = Information[('Beer','Red')]\n",
    "        #find peak\n",
    "        Ux_peaktime.append( timeshift[int(np.mean(np.where(Ux == max(Ux))))])\n",
    "        Uv_peaktime.append( timeshift[int(np.mean(np.where(Uv == max(Uv))))])\n",
    "        Syn_peaktime.append( timeshift[int(np.mean(np.where(Syner == max(Syner))))])\n",
    "        Rdn_peaktime.append( timeshift[int(np.mean(np.where(Redun == max(Redun))))])\n",
    "        MIx_peaktime.append( timeshift[np.argmax(Ux+Redun)])\n",
    "        MIv_peaktime.append( timeshift[np.argmax(Uv+Redun)])\n",
    "        MIxv_peaktime.append( timeshift[np.argmax(Ux+Uv+Redun+Syner)])\n",
    "        \n",
    "        Ux_peakH.append( max(Ux))\n",
    "        Uv_peakH.append( max(Uv))\n",
    "        Syn_peakH.append( max(Syner))\n",
    "        Rdn_peakH.append( max(Redun))\n",
    "        MIx_peakH.append( max(Ux+Redun))\n",
    "        MIv_peakH.append( max(Uv+Redun))\n",
    "        MIxv_peakH.append( max(Ux+Uv+Redun+Syner))\n",
    "        \n",
    "    Ux_peaktime_list.append(np.array(Ux_peaktime).copy())\n",
    "    Uv_peaktime_list.append(np.array(Uv_peaktime).copy())\n",
    "    Syn_peaktime_list.append(np.array(Syn_peaktime).copy())\n",
    "    Rdn_peaktime_list.append(np.array(Rdn_peaktime).copy())\n",
    "    MIx_peaktime_list.append(np.array(MIx_peaktime).copy())\n",
    "    MIv_peaktime_list.append(np.array(MIv_peaktime).copy())\n",
    "    MIxv_peaktime_list.append(np.array(MIxv_peaktime).copy())\n",
    "    \n",
    "    Ux_peakH_list.append(np.array(Ux_peakH).copy())\n",
    "    Uv_peakH_list.append(np.array(Uv_peakH).copy())\n",
    "    Syn_peakH_list.append(np.array(Syn_peakH).copy())\n",
    "    Rdn_peakH_list.append(np.array(Rdn_peakH).copy())\n",
    "    MIx_peakH_list.append(np.array(MIx_peakH).copy())\n",
    "    MIv_peakH_list.append(np.array(MIv_peakH).copy())\n",
    "    MIxv_peakH_list.append(np.array(MIxv_peakH).copy())\n",
    "    \n",
    "    ngd_Ux_peaktime_list.append(np.array(ngd_Ux_peaktime).copy())\n",
    "    ngd_Uv_peaktime_list.append(np.array(ngd_Uv_peaktime).copy())\n",
    "    ngd_Syn_peaktime_list.append(np.array(ngd_Syn_peaktime).copy())\n",
    "    ngd_Rdn_peaktime_list.append(np.array(ngd_Rdn_peaktime).copy())\n",
    "    ngd_MIx_peaktime_list.append(np.array(ngd_MIx_peaktime).copy())\n",
    "    ngd_MIv_peaktime_list.append(np.array(ngd_MIv_peaktime).copy())\n",
    "    ngd_MIxv_peaktime_list.append(np.array(ngd_MIxv_peaktime).copy())\n",
    "    \n",
    "    ngd_Ux_peakH_list.append(np.array(ngd_Ux_peakH).copy())\n",
    "    ngd_Uv_peakH_list.append(np.array(ngd_Uv_peakH).copy())\n",
    "    ngd_Syn_peakH_list.append(np.array(ngd_Syn_peakH).copy())\n",
    "    ngd_Rdn_peakH_list.append(np.array(ngd_Rdn_peakH).copy())\n",
    "    ngd_MIx_peakH_list.append(np.array(ngd_MIx_peakH).copy())\n",
    "    ngd_MIv_peakH_list.append(np.array(ngd_MIv_peakH).copy())\n",
    "    ngd_MIxv_peakH_list.append(np.array(ngd_MIxv_peakH).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XOsave = 0\n",
    "save_folder = 'C:\\\\Users\\\\hydro_leo\\\\Documents\\\\GitHub\\\\python-code\\\\4PID_paper\\\\beta vs. PI\\\\'\n",
    "# save_folder = 'C:\\\\Users\\\\llinc\\\\GitHub\\\\python code\\\\4PID_paper\\\\lambda vs. PI\\\\'\n",
    "name = 'WF_PeakHeights_Fc='+str(Fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different Fc (Peak height & time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "fig_list = []\n",
    "for i in range(len(annots_list)):\n",
    "    fig, (ax2, ax3) = plt.subplots(nrows=1, ncols=2) \n",
    "    fig.set_size_inches(16, 4*(np.sqrt(5)-1))\n",
    "    fig.suptitle(r'$F_c = $'+ str(Fc_list[i]/2)+'Hz,  '+r'$t_{corr}=$'+str(round(t_cor_list[i],3))+'s',y =0.95)\n",
    "    fig_list.append(fig)\n",
    "    ax2.plot(Lambdas,Ux_peakH_list[i], 'r-')\n",
    "    ax2.plot(Lambdas,Uv_peakH_list[i], 'b-')\n",
    "    ax2.plot(Lambdas,Syn_peakH_list[i], 'k-')\n",
    "    ax2.plot(Lambdas,Rdn_peakH_list[i], 'g-')\n",
    "    ax2.plot(Lambdas,ngd_Ux_peakH_list[i], 'r:')\n",
    "    ax2.plot(Lambdas,ngd_Uv_peakH_list[i], 'b:')\n",
    "    ax2.plot(Lambdas,ngd_Syn_peakH_list[i], 'k:')\n",
    "    ax2.plot(Lambdas,ngd_Rdn_peakH_list[i], 'g:')\n",
    "\n",
    "    ax2.set_xlabel(r'$\\lambda $ ')\n",
    "    ax2.set_ylabel(r'Peak Height (bit/s)')\n",
    "    ax2.grid(True)\n",
    "    ax2.legend((r'$U_x$', r'$U_v$', 'synergy', 'redundancy'), loc='best', prop={'size': 'large', 'family': 'monospace'})\n",
    "\n",
    "    \n",
    "\n",
    "    ax3.plot(Lambdas,Ux_peaktime_list[i], 'r-')\n",
    "    ax3.plot(Lambdas,Uv_peaktime_list[i], 'b-')\n",
    "    ax3.plot(Lambdas,Syn_peaktime_list[i], 'k-')\n",
    "    ax3.plot(Lambdas,Rdn_peaktime_list[i], 'g-')\n",
    "    ax3.plot(Lambdas,ngd_Ux_peaktime_list[i], 'r:')\n",
    "    ax3.plot(Lambdas,ngd_Uv_peaktime_list[i], 'b:')\n",
    "    ax3.plot(Lambdas,ngd_Syn_peaktime_list[i], 'k:')\n",
    "    ax3.plot(Lambdas,ngd_Rdn_peaktime_list[i], 'g:')\n",
    "    ax3.set_xlabel(r'$\\lambda$ ')\n",
    "    ax3.set_ylabel('Peak time (s) ')\n",
    "    ax3.legend( (r'$U_x$', r'$U_v$', 'synergy', 'redundancy'), loc='best')\n",
    "    ax3.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if XOsave:\n",
    "    for i in range(len(annots_list)):\n",
    "        name = 'PeakHeightsnTime_Fc='+str(Fc_list[i])\n",
    "        fig_list[i].savefig(save_folder+name+'.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different Fc (Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_list = []\n",
    "for i in range(len(annots_list)):\n",
    "    Phi = ndimage.gaussian_filter1d(Uv_peakH_list[i]/Ux_peakH_list[i], sigma=1, mode='reflect')\n",
    "    ngd_Phi = ndimage.gaussian_filter1d(ngd_Uv_peakH_list[i]/ngd_Ux_peakH_list[i], sigma=1, mode='reflect')\n",
    "    plt.plot(Lambdas,ngd_Phi,linestyle = 'dashed')\n",
    "    plt.plot(Lambdas,Phi)\n",
    "plt.gcf().set_size_inches(6.6, 3.3*(np.sqrt(5)-1))\n",
    "plt.xlabel(r'$\\lambda$ ')\n",
    "plt.ylabel('peak height ratio')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'PeakHeightnTime vs Fc'\n",
    "np.savez(save_folder+name+'.npz', Lambdas=Lambdas, Ux_peakH_list=Ux_peakH_list, Uv_peakH_list=Uv_peakH_list,\n",
    "         Syn_peakH_list=Syn_peakH_list, Rdn_peakH_list=Rdn_peakH_list, Ux_peaktime_list=Ux_peaktime_list, \n",
    "         Uv_peaktime_list=Uv_peaktime_list, Syn_peaktime_list=Syn_peaktime_list, Rdn_peaktime_list=Rdn_peaktime_list,\n",
    "         Fc_list=Fc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_list)): \n",
    "    print(np.std(x_list[i]), np.std(v_list[i]))\n",
    "#     plt.plot(x_list)\n",
    "#     plt.plot(v_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "326px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
