{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "from scipy import signal\n",
    "from scipy.fftpack import fft\n",
    "from scipy import ndimage\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_filter_1d(x,s):\n",
    "    return(np.exp(-x**2/2/s**2))/s/np.sqrt(2*np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback and  Feedforward one layer-1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![C-H-B fig1.png](Markdown%20Figure/C-H-B%20fig1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FB_FF_1l_1D(stimulus, sigma_dict, para_dict, dx, dt, loc_dict = 1):\n",
    "    if loc_dict == 1:\n",
    "        loc_dict = {}\n",
    "        loc_dict['C'] = 1\n",
    "        loc_dict['H'] = 1\n",
    "        \n",
    "    klen = min(max(sigma_dict.values())*3, int(stimulus.shape[1]/2/dx))\n",
    "    xx = np.arange(-klen,klen+dx,dx)\n",
    "    KC = Gaussian_filter_1d(xx,sigma_dict['C'])\n",
    "    KH = Gaussian_filter_1d(xx,sigma_dict['H'])\n",
    "    KB = Gaussian_filter_1d(xx,sigma_dict['B'])\n",
    "    plt.plot(KC)\n",
    "    plt.plot(KH)\n",
    "    plt.plot(KB)\n",
    "    \n",
    "    output = np.zeros_like(stimulus)#y output\n",
    "    zts = np.zeros_like(stimulus)#horizontal\n",
    "    yts = np.zeros_like(stimulus)#horizontal\n",
    "    wts = np.zeros_like(stimulus)#horizontal\n",
    "    sstm = np.zeros_like(stimulus)\n",
    "    rpeak1 = np.zeros(np.shape(stimulus)[0])\n",
    "    rpeak2 = np.zeros(np.shape(stimulus)[0])\n",
    "    rinvertpeak2 = np.zeros(np.shape(stimulus)[0])\n",
    "    \n",
    "    if 'tau_y' in sigma_dict.keys():\n",
    "        T = np.arange(0,int(sigma_dict['tau_y']/dt*8))*dt\n",
    "        Ky=T/sigma_dict['tau_y'] /sigma_dict['tau_y'] *np.exp(-T/sigma_dict['tau_y'])\n",
    "        for j in range(np.shape(stimulus)[1]):\n",
    "            for i in range(len(Ky)-1):\n",
    "                for ii in range(i+1):\n",
    "                    sstm[i,j] += stimulus[ii,j]*Ky[i-ii]*dt\n",
    "            sx = np.convolve(stimulus[:,j],Ky,'valid')*dt\n",
    "            sstm[len(Ky)-1:,j] = sx.copy()\n",
    "    else:\n",
    "        sstm = stimulus.copy()\n",
    "\n",
    "    for i in range(np.shape(stimulus)[0]):\n",
    "        s = sstm[i,:]\n",
    "        rs = np.convolve(s,KC,'same')*dx\n",
    "        ry2z = np.convolve(yts[i-1,:],KH,'same')*dx# feedback from horizontal cell (y convoluted with horitonatl cell receptive field KH)\n",
    "        dyj =(-para_dict['alpha']*yts[i-1,:]+para_dict['k']*(s-para_dict['phi']*zts[i-1,:]))*dt\n",
    "        dzj =(-para_dict['beta']*zts[i-1,:]+para_dict['g']*ry2z)*dt\n",
    "                \n",
    "        yts[i,:] = (yts[i-1,:]+dyj)*loc_dict['C']\n",
    "        zts[i,:] = (zts[i-1,:]+dzj)*loc_dict['H']\n",
    "        ry2w = np.convolve(yts[i-1,:],KB,'same')*dx# feedback from horizontal cell (y convoluted with horitonatl cell receptive field KH)\n",
    "        rz = np.convolve(zts[i-1,:],KH,'same')*dx# feedback from horizontal cell (z convoluted with horitonatl cell receptive field KH)\n",
    "        dwj =(-para_dict['gramma']*wts[i-2,:]+para_dict['p']*((1-para_dict['psy'])*ry2w-para_dict['psy']*zts[i-1,:]))*dt\n",
    "\n",
    "        wts[i-1,:] = (wts[i-2,:]+dwj)\n",
    "        maxpos1 = np.argmax(yts[i,:])\n",
    "        rpeak1[i]= maxpos1*dx\n",
    "        maxpos2 = np.argmax(wts[i-1,:])\n",
    "        rpeak2[i-1]= maxpos2*dx\n",
    "        maxipos2 = np.argmin(wts[i-1,:])\n",
    "        rinvertpeak2[i-1]= maxipos2*dx\n",
    "    \n",
    "    ry2w = np.convolve(yts[i,:],KB,'same')*dx# feedback from horizontal cell (y convoluted with horitonatl cell receptive field KH)\n",
    "    rz = np.convolve(zts[i,:],KH,'same')*dx# feedback from horizontal cell (z convoluted with horitonatl cell receptive field KH)\n",
    "    dwj =(-para_dict['gramma']*wts[i-1,:]+para_dict['p']*((1-para_dict['psy'])*ry2w-para_dict['psy']*rz))*dt\n",
    "    wts[i,:] = (wts[i-1,:]+dwj)\n",
    "    maxpos2 = np.argmax(wts[i,:])\n",
    "    rpeak2[i]= maxpos2*dx\n",
    "    maxipos2 = np.argmin(wts[i,:])\n",
    "    rinvertpeak2[i]= maxipos2*dx\n",
    "    return wts, zts, yts, rpeak1, rpeak2, rinvertpeak2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bipolar(yts, zts, sigma_dict, para_dict, dx, dt, loc_dict = 1):\n",
    "    if loc_dict == 1:\n",
    "        loc_dict = {}\n",
    "        loc_dict['C'] = 1\n",
    "        loc_dict['H'] = 1\n",
    "        \n",
    "    klen = min(max(sigma_dict.values())*3, int(yts.shape[1]/2/dx))\n",
    "    xx = np.arange(-klen,klen+dx,dx)\n",
    "    KC = Gaussian_filter_1d(xx,sigma_dict['C'])\n",
    "    KH = Gaussian_filter_1d(xx,sigma_dict['H'])\n",
    "    KB = Gaussian_filter_1d(xx,sigma_dict['B'])\n",
    "    plt.plot(KC)\n",
    "    plt.plot(KH)\n",
    "    plt.plot(KB)\n",
    "    \n",
    "    wts = np.zeros_like(yts)#horizontal\n",
    "    rpeak2 = np.zeros(np.shape(yts)[0])\n",
    "    rinvertpeak2 = np.zeros(np.shape(yts)[0])\n",
    "    \n",
    "\n",
    "    for i in range(np.shape(yts)[0]):\n",
    "        ry2w = np.convolve(yts[i,:],KB,'same')*dx# feedback from horizontal cell (y convoluted with horitonatl cell receptive field KH)\n",
    "        rz = np.convolve(zts[i,:],KH,'same')*dx# feedback from horizontal cell (z convoluted with horitonatl cell receptive field KH)\n",
    "        dwj =(-para_dict['gramma']*wts[i-1,:]+para_dict['p']*((1-para_dict['psy'])*ry2w-para_dict['psy']*rz))*dt\n",
    "        wts[i,:] = (wts[i-1,:]+dwj)\n",
    "        maxpos2 = np.argmax(wts[i,:])\n",
    "        rpeak2[i]= maxpos2*dx\n",
    "        maxipos2 = np.argmin(wts[i,:])\n",
    "        rinvertpeak2[i]= maxipos2*dx\n",
    "    \n",
    "\n",
    "    return wts, rpeak2, rinvertpeak2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal State "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EqualState assign states with equal possibility for input array x\n",
    "def EqualState(x, num_state):\n",
    "    xs=np.sort(x)\n",
    "    binlen=int(len(x)/num_state-0.5) #round\n",
    "    edges = xs[np.arange(num_state+1)*binlen]\n",
    "    xstate=np.zeros(len(x))\n",
    "    for i in range(num_state):\n",
    "        xstate[x>=edges[i]] = i\n",
    "    xstate = xstate.astype(int)\n",
    "    return xstate, edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PIfunc(r, x, v, dt, window):\n",
    "    negshift=window[0] # second\n",
    "    posshift=window[1] # second\n",
    "    shiftlen=(posshift-negshift)/dt+1\n",
    "    timeshift=np.linspace(negshift,posshift,int(shiftlen))\n",
    "    bitshift=np.linspace(negshift/dt,posshift/dt,int(shiftlen),dtype = 'int16')\n",
    "    Information = dict()\n",
    "    Information[('BROJA_2PID','SI')]=np.zeros(len(bitshift))\n",
    "    Information[('BROJA_2PID','UIx')]=np.zeros(len(bitshift))\n",
    "    Information[('BROJA_2PID','UIv')]=np.zeros(len(bitshift))\n",
    "    Information[('BROJA_2PID','CI')]=np.zeros(len(bitshift))\n",
    "    Information[('Beer','Red')]=np.zeros(len(bitshift))\n",
    "    Information[('Beer','UIx')]=np.zeros(len(bitshift))\n",
    "    Information[('Beer','UIv')]=np.zeros(len(bitshift))\n",
    "    Information[('Beer','Syn')]=np.zeros(len(bitshift))\n",
    "    \n",
    "    Information[('test','SI')]=np.zeros(len(bitshift))\n",
    "    Information[('test','UIx')]=np.zeros(len(bitshift))\n",
    "    Information[('test','UIv')]=np.zeros(len(bitshift))\n",
    "    Information[('test','CI')]=np.zeros(len(bitshift))\n",
    "    Redun =np.zeros(len(bitshift))\n",
    "    MIxr=np.zeros(len(bitshift))\n",
    "    MIvr=np.zeros(len(bitshift))\n",
    "    MIxvR=np.zeros(len(bitshift))\n",
    "    parms = dict()\n",
    "    parms['max_iters'] = 20\n",
    "    # shifted data\n",
    "    # shift>0 => y shifted to positive side\n",
    "    for i in range(len(bitshift)):\n",
    "        xx=[]\n",
    "        vv=[]\n",
    "        rr=[]\n",
    "        shift=bitshift[i]\n",
    "        if shift>0:\n",
    "            xx=x[shift:]\n",
    "            vv=v[shift:]\n",
    "            rr=r[:(-1*shift)]\n",
    "        elif shift==0:\n",
    "            xx=x\n",
    "            vv=v\n",
    "            rr=r\n",
    "        elif shift<0:\n",
    "            xx=x[:shift]\n",
    "            vv=v[:shift]\n",
    "            rr=r[(-1*shift):]\n",
    "        #find weight of each states by 3D histogram \n",
    "        xedges = np.append(np.unique(xx),(max(xx)+1))\n",
    "        vedges = np.append(np.unique(vv),(max(vv)+1))\n",
    "        redges = np.append(np.unique(rr),(max(rr)+1))\n",
    "        dat = np.concatenate((xx[:,np.newaxis], vv[:,np.newaxis],rr[:,np.newaxis]), axis=1)\n",
    "        N, edges = np.histogramdd(dat, bins=(xedges, vedges, redges))\n",
    "        #Calculate all kinds of probability and make sure the shape of them, 0 -> x, 1 -> v, 2 -> r\n",
    "        px=(np.sum(N,axis=(1,2))/np.sum(N))[:, np.newaxis, np.newaxis]\n",
    "        pv=(np.sum(N,axis=(0,2))/np.sum(N))[np.newaxis, :, np.newaxis]\n",
    "        pr=(np.sum(N,axis=(0,1))/np.sum(N))[np.newaxis ,np.newaxis, :]\n",
    "        pxv=(np.sum(N,axis=2)/np.sum(N))[:, :, np.newaxis]\n",
    "        pxr=(np.sum(N,axis=1)/np.sum(N))[:, np.newaxis, :]\n",
    "        pvr=(np.sum(N,axis=0)/np.sum(N))[np.newaxis, :, :]\n",
    "        pxvr=(N/np.sum(N))\n",
    "        \n",
    "        Information[('test','UIx')][i] = np.nansum(pxvr*np.log2(pxvr*px/pxv/pxr))/dt\n",
    "        Information[('test','UIv')][i] = np.nansum(pxvr*np.log2(pxvr*pv/pxv/pvr))/dt\n",
    "                \n",
    "#         PDF=Histo3D2Dict(pxvr)\n",
    "#         BROJA_2PID = pid(PDF, cone_solver=\"ECOS\", output=0, **parms)\n",
    "#         Information[('BROJA_2PID','SI')][i]=BROJA_2PID['SI']/dt\n",
    "#         Information[('BROJA_2PID','UIx')][i]=BROJA_2PID['UIY']/dt\n",
    "#         Information[('BROJA_2PID','UIv')][i]=BROJA_2PID['UIZ']/dt\n",
    "#         Information[('BROJA_2PID','CI')][i]=BROJA_2PID['CI']/dt\n",
    "        \n",
    "\n",
    "        MIxr=np.nansum(pxr*np.log2(pxr/px/pr))/dt\n",
    "        MIvr=np.nansum(pvr*np.log2(pvr/pv/pr))/dt\n",
    "        MIxvR=np.nansum(pxvr*np.log2(pxvr/pxv/pr))/dt\n",
    "        PI_xR = np.nansum(pxr*np.log2(pxr/px/pr), axis = (0,1))\n",
    "        PI_vR = np.nansum(pvr*np.log2(pvr/pv/pr), axis = (0,1))\n",
    "        R = sum(np.minimum(PI_xR, PI_vR))/dt\n",
    "        Information[('Beer','Red')][i] = R\n",
    "        Information[('Beer','UIx')][i] = MIxr - R\n",
    "        Information[('Beer','UIv')][i] = MIvr - R\n",
    "        Information[('Beer','Syn')][i] = MIxvR - MIxr - MIvr + R\n",
    "\n",
    "    return timeshift, Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike_Time_Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spike_Time_Generater(rdt, dt, Garmma=1):\n",
    "    rdt = rdt*Garmma\n",
    "    Spike_time = []\n",
    "    \n",
    "    counter = 0\n",
    "    post_remainer_c = 0\n",
    "    p = 1\n",
    "    while True:\n",
    "        the_random_number = np.random.rand()\n",
    "        while (the_random_number < p and counter < len(rdt)):\n",
    "            p *= np.exp(-rdt[counter])\n",
    "            counter += 1\n",
    "        if counter >= len(rdt):\n",
    "            break\n",
    "        remainer_c = -np.log(p/the_random_number)/rdt[counter-1]\n",
    "#         if remainer_c>=1 or remainer_c<=0:\n",
    "#             print('shit!')\n",
    "        Spike_time.append(dt*(counter-remainer_c))\n",
    "        p = np.exp(-remainer_c*rdt[counter-1])\n",
    "    return Spike_time[::Garmma]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function\n",
    "def NL(x,theta=0):\n",
    "    y = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        if x[i]- theta>0:\n",
    "            y[i]= x[i]-theta\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CKC's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.01\n",
    "\n",
    "sigma_dict = dict()\n",
    "sigma_dict['H'] = 1\n",
    "sigma_dict['C'] = sigma_dict['H']*0.2# RF size of cone cell\n",
    "dx = sigma_dict['H']/200. #1/sstep\n",
    " \n",
    "#sigma_dict['tau_y'] = 0.01                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "\n",
    "#Width setting\n",
    "Dynamical_range = 6*sigma_dict['H']/dx #188-16 pixels\n",
    "hw = 3*Dynamical_range*dx/22 #half bar width  #8 pixels\n",
    "xlen = 10*sigma_dict['H'] #spatial extend of simulation\n",
    "tempx = np.arange(0,xlen,dx)\n",
    "\n",
    "para_dict = {}\n",
    "para_dict['alpha'] = 40.\n",
    "para_dict['beta'] = 2.\n",
    "para_dict['k'] = 40.\n",
    "para_dict['phi'] = 5.\n",
    "para_dict['g'] = 2.\n",
    "\n",
    "para_dict['gramma'] = 100.\n",
    "para_dict['p'] = 100.\n",
    "para_dict['psy'] = 0.2\n",
    "\n",
    "sigma_dict['B'] = sigma_dict['H']*0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leo's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = 0.001\n",
    "\n",
    "# NGD_sigma_dict = dict()\n",
    "# NGD_sigma_dict['H'] = 1\n",
    "# NGD_sigma_dict['C'] = NGD_sigma_dict['H']*0.75# RF size of cone cell\n",
    "# dx = NGD_sigma_dict['H']/40\n",
    " \n",
    "# #sigma_dict['tau_y'] = 0.01                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "\n",
    "# #Width setting\n",
    "# Dynamical_range = 6*NGD_sigma_dict['H']/dx #188-16 pixels\n",
    "# hw = 3*Dynamical_range*dx/22 #half bar width  #8 pixels\n",
    "# xlen = 50*NGD_sigma_dict['H'] #spatial extend of simulation\n",
    "# tempx = np.arange(0,xlen,dx)\n",
    "\n",
    "# NGD_para_dict = {}\n",
    "# NGD_para_dict['alpha'] = 40.\n",
    "# NGD_para_dict['beta'] = 2.\n",
    "# NGD_para_dict['k'] = 50.\n",
    "# NGD_para_dict['phi'] = 20.\n",
    "# NGD_para_dict['g'] = 2.\n",
    "\n",
    "\n",
    "# FBFF_sigma_dict = NGD_sigma_dict.copy()\n",
    "# FBFF_para_dict = NGD_para_dict.copy()\n",
    "# FBFF_para_dict['gramma'] = 40.\n",
    "# FBFF_para_dict['p'] = 40.\n",
    "# FBFF_para_dict['psy'] = 1.2\n",
    "\n",
    "# FBFF_sigma_dict['B'] = FBFF_sigma_dict['H']*0.5\n",
    "\n",
    "\n",
    "# FFFB_para_dict, FFFB_sigma_dict = {}, {}\n",
    "# FFFB_para_dict['alpha2'] = NGD_para_dict['alpha']*2\n",
    "# FFFB_para_dict['beta2'] = NGD_para_dict['beta']*2\n",
    "# FFFB_para_dict['k2'] = NGD_para_dict['k']*2\n",
    "# FFFB_para_dict['phi'] = 1\n",
    "# FFFB_para_dict['psy'] = FBFF_para_dict['psy']\n",
    "# FFFB_para_dict['g2'] = NGD_para_dict['g']*2\n",
    "\n",
    "# FFFB_para_dict['alpha1'] = NGD_para_dict['alpha']\n",
    "# FFFB_para_dict['beta1'] = NGD_para_dict['beta']\n",
    "# FFFB_para_dict['k1'] = NGD_para_dict['k']\n",
    "# FFFB_para_dict['g1'] = NGD_para_dict['g']\n",
    "\n",
    "# FFFB_sigma_dict['H'] =  NGD_sigma_dict['H']\n",
    "# FFFB_sigma_dict['B'] = NGD_sigma_dict['C']\n",
    "# FFFB_sigma_dict['A'] = FFFB_sigma_dict['B']*2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstep = int(1.6/dt)\n",
    "moving_bar = np.zeros([nstep, int(xlen/dx)])\n",
    "pos = 0\n",
    "v = 2.5*hw/dx #sstep/s\n",
    "pos = 600\n",
    "SM_speak = np.zeros(nstep)\n",
    "for i in range(nstep):\n",
    "    pos = pos+v*dt\n",
    "    moving_bar[i,max(int(round(pos-hw/dx)), 0):min(int(round(pos+hw/dx)), int(xlen/dx))] = 1\n",
    "    SM_speak[i] = pos*dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback and  Feedforward one layer-1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SbS_y, zts, yts, rpeak1, rpeak2, rinvertpeak2 = FB_FF_1l_1D(moving_bar, sigma_dict, para_dict, dx, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####PLot numerical solution########\n",
    "plt.plot(tempx,SbS_y.T[:,-1],'b')#numerical solution\n",
    "plt.plot(tempx,zts.T[:,-1],'r')#numerical solution\n",
    "plt.plot(tempx,yts.T[:,-1],'g')#numerical solution\n",
    "plt.plot(tempx,moving_bar.T[:,-1]*max(yts.T[:,-1]),'y')\n",
    "# plt.xlim([25, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax2, ax3) = plt.subplots(nrows=1, ncols=2)\n",
    "ax2.imshow(moving_bar)\n",
    "ax2.set_title('moving_bar')\n",
    "ax3.imshow(SbS_y)\n",
    "ax3.set_title('step by step output')\n",
    "fig.set_size_inches(15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(((rpeak1-SM_speak)/hw))\n",
    "plt.plot(((rpeak2-SM_speak)/hw))\n",
    "# plt.plot(((rinvertpeak2-SM_speak)/hw)[:])\n",
    "# plt.xlim([100,nstep])\n",
    "plt.ylim([-0.5,2])\n",
    "plt.grid()\n",
    "plt.ylabel('preceeding (unit = half width)')\n",
    "plt.xlabel('temporal steps')\n",
    "plt.title('prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\Psy vs. prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psy_list = np.arange(0,1.1,0.1)\n",
    "BoverH_list = np.arange(0.1,1.7,0.1)\n",
    "tabel1 = np.zeros((len(psy_list), len(BoverH_list)))\n",
    "tabel2 = np.zeros((len(psy_list), len(BoverH_list)))\n",
    "tabel3 = np.zeros((len(psy_list), len(BoverH_list)))\n",
    "for i in range(len(psy_list)):\n",
    "    for j in range(len(BoverH_list)):\n",
    "        para_dict['psy'] = psy_list[i]\n",
    "        sigma_dict['B'] = sigma_dict['H']*BoverH_list[j]\n",
    "        _, _, _,rpeak1, rpeak2, rinvertpeak2 = FB_FF_1l_1D(moving_bar, sigma_dict, para_dict, dx, dt)\n",
    "        tabel1[i,j]=((rpeak1-SM_speak)/hw)[-1]\n",
    "        tabel2[i,j]=((rpeak2-SM_speak)/hw)[-1]\n",
    "        tabel3[i,j]=((rinvertpeak2-SM_speak)/hw)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax2, ax3, ax4) = plt.subplots(nrows=1, ncols=3)\n",
    "ax2.imshow(tabel1)\n",
    "ax3.imshow(tabel2)\n",
    "ax4.imshow(tabel3)\n",
    "# ax3.colorbar()\n",
    "ax3.set_yticks(range(len(psy_list)))\n",
    "ax3.set_yticklabels(np.round(psy_list,2))\n",
    "ax3.set_xticks(range(len(BoverH_list)))\n",
    "ax3.set_xticklabels(np.round(BoverH_list,2))\n",
    "fig.set_size_inches(15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axis = fig.gca(projection='3d')\n",
    " \n",
    "#產出X,Y,Z數據\n",
    "x0 = psy_list\n",
    "x1 = BoverH_list\n",
    "X, Y = np.meshgrid(x1, x0)\n",
    " \n",
    "#畫圖\n",
    "surface = axis.plot_surface(X, Y, tabel2, rstride=1, cstride=1, cmap='coolwarm_r')\n",
    "surface2 = axis.plot_wireframe(X, Y, tabel1, rstride=2, cstride=2, color = 'grey')\n",
    "fig.colorbar(surface, shrink=1.0, aspect=20)\n",
    " \n",
    "# 設置圖表訊息\n",
    "plt.ylabel(r'$\\Psi$', fontsize=16)\n",
    "plt.xlabel(r\"$\\sigma_B/\\sigma_H$\", fontsize=16)\n",
    " \n",
    "fig.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LPOU-1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "Tot=300\n",
    "T=np.arange(dt,Tot,dt)\n",
    "# HMM ; input\n",
    "Gamma=4.5\n",
    "Omega =Gamma/2.12\n",
    "D = 27*10**5\n",
    "HMM=np.zeros(len(T))\n",
    "vL =np.zeros(len(T))\n",
    "mu, sigma = 0, 1\n",
    "for i in range(len(T)-1):\n",
    "    HMM[i+1]=HMM[i]+vL[i]*dt\n",
    "    vL[i+1]=vL[i]*(1-dt*Gamma)- Omega**2*HMM[i]*dt+math.sqrt(D*dt)*np.random.normal(mu,sigma)\n",
    "    \n",
    "# OU ; input\n",
    "tau= 1\n",
    "D = 27*10**5\n",
    "OU=np.zeros(len(T))\n",
    "mu, sigma = 0, 1\n",
    "for i in range(len(T)-1):\n",
    "    OU[i+1]=OU[i]*(1-dt/tau)+math.sqrt(D*dt)*np.random.normal(mu,sigma)\n",
    "    \n",
    "# filtering for OUSmoothed\n",
    "cutoffFreq = 1\n",
    "b, a = signal.butter(2, 2*cutoffFreq*dt, btype='low', analog=False)\n",
    "LPOU = signal.filtfilt(b, a, OU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LPOU_bar = np.zeros([len(T), int(xlen/dx)])\n",
    "speak = (LPOU-min(LPOU))/(max(LPOU)-min(LPOU))*Dynamical_range\n",
    "speak = speak-np.mean(speak)+int(xlen/dx/2)\n",
    "for i in range(len(T)):\n",
    "    pos = speak[i]\n",
    "    min_pos = max(int(pos-hw/dx), 0)\n",
    "    max_pos = min(int(pos+hw/dx), int(xlen/dx))\n",
    "    LPOU_bar[i,min_pos:max_pos] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPOU_bar = np.abs(LPOU_bar-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPOU_bar = np.fliplr(LPOU_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign states\n",
    "x = speak.copy()*dt\n",
    "x = x.astype(float)\n",
    "# x = (x-np.mean(x))/np.std(x)\n",
    "v = ndimage.gaussian_filter1d(x.copy(), sigma=5, order=1, mode='reflect') / dt\n",
    "# v = findiff.FinDiff(0, dt, acc=4)(x)\n",
    "xstate, _= EqualState(x, 6)\n",
    "vstate, _= EqualState(v, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback and  Feedforward one layer-1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XOon = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts, zts, yts ,_,_,_ = FB_FF_1l_1D(LPOU_bar, sigma_dict, para_dict, dx, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####PLot numerical solution########\n",
    "plt.plot(tempx,wts.T[:,-1],'b')#numerical solution\n",
    "plt.plot(tempx,zts.T[:,-1],'r')#numerical solution\n",
    "plt.plot(tempx,yts.T[:,-1],'g')#numerical solution\n",
    "plt.legend( ('bipolar', 'horizontal', 'cone'), loc='best', prop={'size': 'large', 'family': 'monospace'})\n",
    "# plt.xlim([15, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax2, ax3) = plt.subplots(nrows=1, ncols=2)\n",
    "ax2.imshow(LPOU_bar[:2000])\n",
    "ax2.set_title('moving_bar')\n",
    "ax3.imshow(wts[:2000])\n",
    "ax3.set_title('step by step output')\n",
    "fig.set_size_inches(15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sindex = int(xlen/dx/2)\n",
    "ww = np.zeros(wts.shape[0])\n",
    "yy = np.zeros(yts.shape[0])\n",
    "for i in range( wts.shape[0]):\n",
    "    ww[i] = wts[i][Sindex]\n",
    "    yy[i] = yts[i][Sindex]\n",
    "fig, (ax2,ax3) = plt.subplots(nrows=1, ncols=2) \n",
    "ax3.plot(ww)\n",
    "ax2.plot(yy)\n",
    "fig.set_size_inches(8,4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = NL(-np.mean(yy)+yy, 1*np.std(yy))\n",
    "ratio = sum(cr)/Tot/3\n",
    "cFakeSpike = Spike_Time_Generater(cr/ratio, dt, 10)\n",
    "crstate,_  = np.histogram(cFakeSpike, np.append(0,T))\n",
    "plt.plot(crstate)\n",
    "plt.plot(cr/max(cr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window = [-1,1] # second\n",
    "timeshift, cInformation = PIfunc(crstate, xstate, vstate, dt, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax2,ax3) = plt.subplots(nrows=1, ncols=2) \n",
    "fig.suptitle('cone', y=0.95, fontsize=20)\n",
    "ax2.plot(timeshift,cInformation[('Beer','UIx')], 'r-')\n",
    "ax2.plot(timeshift,cInformation[('Beer','UIv')], 'b-')\n",
    "ax2.plot(timeshift,cInformation[('Beer','Syn')], 'k-')\n",
    "ax2.plot(timeshift,cInformation[('Beer','Red')], 'g-')\n",
    "ax2.set_title('Partial Information (Beer)')\n",
    "ax2.set_xlabel('Time(s)')\n",
    "ax2.set_ylabel('Information(bit/s)')\n",
    "ax2.legend( (r'$U_x$', r'$U_v$', 'synergy', 'redundancy'), loc='best', prop={'size': 'large', 'family': 'monospace'})\n",
    "ax2.grid()\n",
    "\n",
    "ax3.plot(timeshift,cInformation[('Beer','UIx')]+cInformation[('Beer','Red')], 'r-')\n",
    "ax3.plot(timeshift,cInformation[('Beer','UIv')]+cInformation[('Beer','Red')], 'b-')\n",
    "ax3.plot(timeshift,cInformation[('Beer','Syn')]+cInformation[('Beer','Red')]+cInformation[('Beer','UIv')]+cInformation[('Beer','UIx')], 'k-')\n",
    "ax3.plot(timeshift,2*cInformation[('Beer','Red')]+cInformation[('Beer','UIv')]+cInformation[('Beer','UIx')], 'm-')\n",
    "ax3.set_title('Mutual Information')\n",
    "ax3.set_xlabel(r'$\\delta t(s)$')\n",
    "ax3.set_ylabel('Information(bit/s)')\n",
    "ax3.legend( ('MI(x,r)', 'MI(v,r)', 'MI({x,v},r)', 'MI(x,r)+MI(v,r)'), loc='best', prop={'size': 'large', 'family': 'monospace'})\n",
    "ax3.grid()\n",
    "\n",
    "fig.set_size_inches(15, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cMIpeaktime = np.round(timeshift[np.argmax(cInformation[('Beer','UIx')]+cInformation[('Beer','Red')])],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if XOon == 1:\n",
    "    r = NL(-np.mean(ww)+ww, 1*np.std(ww))\n",
    "else:\n",
    "    r = NL(np.mean(ww)-ww, 1*np.std(ww))\n",
    "ratio = sum(r)/Tot/3\n",
    "FakeSpike = Spike_Time_Generater(r/ratio, dt, 10)\n",
    "rstate,_  = np.histogram(FakeSpike, np.append(0,T))\n",
    "plt.plot(rstate)\n",
    "plt.plot(r/max(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window = [-1,1] # second\n",
    "timeshift, Information = PIfunc(rstate, xstate, vstate, dt, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax2,ax3) = plt.subplots(nrows=1, ncols=2)\n",
    "fig.suptitle('bipolar', y=0.95, fontsize=20)\n",
    "ax2.plot(timeshift,Information[('Beer','UIx')], 'r-')\n",
    "ax2.plot(timeshift,Information[('Beer','UIv')], 'b-')\n",
    "ax2.plot(timeshift,Information[('Beer','Syn')], 'k-')\n",
    "ax2.plot(timeshift,Information[('Beer','Red')], 'g-')\n",
    "ax2.set_title('Partial Information (Beer)')\n",
    "ax2.set_xlabel('Time(s)')\n",
    "ax2.set_ylabel('Information(bit/s)')\n",
    "ax2.legend( (r'$U_x$', r'$U_v$', 'synergy', 'redundancy'), loc='best', prop={'size': 'large', 'family': 'monospace'})\n",
    "ax2.grid()\n",
    "\n",
    "ax3.plot(timeshift,Information[('Beer','UIx')]+Information[('Beer','Red')], 'r-')\n",
    "ax3.plot(timeshift,Information[('Beer','UIv')]+Information[('Beer','Red')], 'b-')\n",
    "ax3.plot(timeshift,Information[('Beer','Syn')]+Information[('Beer','Red')]+Information[('Beer','UIv')]+Information[('Beer','UIx')], 'k-')\n",
    "ax3.plot(timeshift,2*Information[('Beer','Red')]+Information[('Beer','UIv')]+Information[('Beer','UIx')], 'm-')\n",
    "ax3.set_title('Mutual Information')\n",
    "ax3.set_xlabel(r'$\\delta t(s)$')\n",
    "ax3.set_ylabel('Information(bit/s)')\n",
    "ax3.legend( ('MI(x,r)', 'MI(v,r)', 'MI({x,v},r)', 'MI(x,r)+MI(v,r)'), loc='best', prop={'size': 'large', 'family': 'monospace'})\n",
    "ax3.grid()\n",
    "\n",
    "fig.set_size_inches(15, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\Psi vs. MI peak time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psy_list = np.arange(0,1.1,0.1)\n",
    "BoverH_list = np.arange(0.1,1.6,0.1)\n",
    "MItabel = np.zeros((len(psy_list), len(BoverH_list)))\n",
    "for i in range(len(psy_list)):\n",
    "    for j in range(len(BoverH_list)):\n",
    "        para_dict['psy'] = psy_list[i]\n",
    "        sigma_dict['B'] = sigma_dict['H']*BoverH_list[j]\n",
    "        \n",
    "\n",
    "        wts,_,_ = Bipolar(yts, zts, sigma_dict, para_dict, dx, dt)\n",
    "        for k in range( wts.shape[0]):\n",
    "            ww[k] = wts[k][Sindex]\n",
    "            \n",
    "        if XOon == 1:\n",
    "            r = NL(-np.mean(ww)+ww, 1*np.std(ww))\n",
    "        else:\n",
    "            r = NL(np.mean(ww)-ww, 1*np.std(ww))\n",
    "        ratio = sum(r)/Tot/3\n",
    "        FakeSpike = Spike_Time_Generater(r/ratio, dt, 10)\n",
    "        rstate,_  = np.histogram(FakeSpike, np.append(0,T))\n",
    "        window = [-1,1] # second\n",
    "        timeshift, Information = PIfunc(rstate, xstate, vstate, dt, window)\n",
    "        MItabel[i,j] = np.round(timeshift[np.argmax(Information[('Beer','UIx')]+Information[('Beer','Red')])],3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(MItabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axis = fig.gca(projection='3d')\n",
    " \n",
    "#產出X,Y,Z數據\n",
    "x0 = psy_list\n",
    "x1 = BoverH_list\n",
    "X, Y = np.meshgrid(x1, x0)\n",
    " \n",
    "#畫圖\n",
    "surface = axis.plot_surface(X, Y, MItabel, rstride=1, cstride=1, cmap='coolwarm_r')\n",
    "# surface2 = axis.plot_wireframe(X, Y, tabel1, rstride=2, cstride=2, color = 'grey')\n",
    "fig.colorbar(surface, shrink=1.0, aspect=20)\n",
    " \n",
    "# 設置圖表訊息\n",
    "plt.ylabel(r'$\\Psi$', fontsize=16)\n",
    "plt.xlabel(r\"$\\sigma_B/\\sigma_H$\", fontsize=16)\n",
    " \n",
    "fig.set_size_inches(16,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "289.703px",
    "left": "1548.44px",
    "right": "20px",
    "top": "117px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
